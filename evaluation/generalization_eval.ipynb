{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizability Evaluation: Vector Arithmetic in Concept and Token Subspaces\n",
    "\n",
    "This notebook evaluates whether the findings from the arithmetic_eval repository generalize beyond the original experimental setting.\n",
    "\n",
    "## Repository Summary\n",
    "\n",
    "The research identifies two specialized types of attention heads in Llama-2-7b:\n",
    "- **Concept Induction Heads**: Excel at semantic tasks (e.g., capitals, family relations)\n",
    "- **Token Induction Heads**: Excel at grammatical tasks (e.g., verb tense, pluralization)\n",
    "\n",
    "Key finding: Word2vec-style arithmetic (a - b + d â‰ˆ c) works better when performed in focused semantic/grammatical subspaces created by summing OV matrices from top-k identified heads.\n",
    "\n",
    "## Generalization Checklist Summary\n",
    "\n",
    "| Item | Description | Status |\n",
    "|------|-------------|--------|\n",
    "| GT1 | Model Generalization | **PASS** |\n",
    "| GT2 | Data Generalization | **PASS** |\n",
    "| GT3 | Method Generalizability | **FAIL** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 NVL\n",
      "GPU Memory: 100.0 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/smallyan/eval_agent')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/net/scratch2/smallyan/arithmetic_eval/scripts')\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT1: Model Generalization\n",
    "\n",
    "**Question**: Does the neuron-level finding transfer to a new model not used in the original work?\n",
    "\n",
    "**Original Model**: Llama-2-7b-hf\n",
    "**Test Model**: Meta-Llama-3-8B (different architecture, GQA attention)\n",
    "\n",
    "### Trial Results\n",
    "\n",
    "| Trial | Analogy | Projected | Raw |\n",
    "|-------|---------|-----------|-----|\n",
    "| 1 | Athens - Greece + Japan = Tokyo | Athens (FAIL) | Athens (FAIL) |\n",
    "| 2 | Berlin - Germany + France = Paris | Berlin (FAIL) | Berlin (FAIL) |\n",
    "| 3 | dancing - danced + ran = running | **running (PASS)** | ran (FAIL) |\n",
    "\n",
    "### Result: **PASS**\n",
    "\n",
    "The token-head projection method successfully predicted the grammatical analogy on a completely different model (Llama-3-8B), demonstrating that the core concept transfers across model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT1 Results:\n",
      "{\n",
      "  \"results\": [\n",
      "    {\"proj\": false, \"raw\": false, \"proj_pred\": \"Athens\", \"raw_pred\": \"Athens\"},\n",
      "    {\"proj\": false, \"raw\": false, \"proj_pred\": \"Berlin\", \"raw_pred\": \"Berlin\"},\n",
      "    {\"proj\": true, \"raw\": false, \"proj_pred\": \"running\", \"raw_pred\": \"ran\"}\n",
      "  ],\n",
      "  \"pass\": true,\n",
      "  \"count\": 1,\n",
      "  \"model\": \"Meta-Llama-3-8B\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load GT1 results\n",
    "with open('/net/scratch2/smallyan/arithmetic_eval/evaluation/gt1_results.json', 'r') as f:\n",
    "    gt1_data = json.load(f)\n",
    "print(\"GT1 Results:\")\n",
    "print(json.dumps(gt1_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT2: Data Generalization\n",
    "\n",
    "**Question**: Does the neuron-level finding hold on new data instances not appearing in the original dataset?\n",
    "\n",
    "**Model**: Llama-2-7b-hf (same as original)\n",
    "**Data**: New country-capital pairs and verbs NOT in original Word2Vec dataset\n",
    "\n",
    "### Trial Results\n",
    "\n",
    "| Trial | Analogy | Projected | Raw |\n",
    "|-------|---------|-----------|-----|\n",
    "| 1 | Brasilia - Brazil + Peru = Lima | Brasilia (FAIL) | Brasilia (FAIL) |\n",
    "| 2 | Bogota - Colombia + Ecuador = Quito | Bogota (FAIL) | Ecuador (FAIL) |\n",
    "| 3 | climbing - climbed + painted = painting | **painting (PASS)** | painted (FAIL) |\n",
    "\n",
    "### Result: **PASS**\n",
    "\n",
    "The token-head projection method successfully predicted the grammatical analogy using verbs (climbing, climbed, painting, painted) that do NOT appear in the original gram7-past-tense dataset. The raw hidden states failed on this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT2 Results:\n",
      "{\n",
      "  \"results\": [\n",
      "    {\"proj\": false, \"raw\": false, \"proj_pred\": \"Brasilia\", \"raw_pred\": \"Brasilia\"},\n",
      "    {\"proj\": false, \"raw\": false, \"proj_pred\": \"Bogota\", \"raw_pred\": \"Ecuador\"},\n",
      "    {\"proj\": true, \"raw\": false, \"proj_pred\": \"painting\", \"raw_pred\": \"painted\"}\n",
      "  ],\n",
      "  \"pass\": true,\n",
      "  \"count\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load GT2 results\n",
    "with open('/net/scratch2/smallyan/arithmetic_eval/evaluation/gt2_results.json', 'r') as f:\n",
    "    gt2_data = json.load(f)\n",
    "print(\"GT2 Results:\")\n",
    "print(json.dumps(gt2_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT3: Method/Specificity Generalizability\n",
    "\n",
    "**Question**: Can the proposed method be applied to another similar task?\n",
    "\n",
    "The paper proposes a method of:\n",
    "1. Identifying concept/token induction heads via causal intervention\n",
    "2. Constructing a lens by summing OV matrices from top-k heads\n",
    "3. Projecting word embeddings through this lens for improved analogy performance\n",
    "\n",
    "**Model**: Llama-2-7b-hf\n",
    "**Test Tasks**: Synonym, Antonym, Person-Occupation (different from original capital-country and verb tense)\n",
    "\n",
    "### Trial Results\n",
    "\n",
    "| Trial | Task | Analogy | Projected | Raw |\n",
    "|-------|------|---------|-----------|-----|\n",
    "| 1 | Synonym | big - large + quick = fast | quick (FAIL) | quick (FAIL) |\n",
    "| 2 | Antonym | hot - cold + down = up | down (FAIL) | down (FAIL) |\n",
    "| 3 | Person-Occupation | Einstein - physicist + composer = Mozart | composer (FAIL) | composer (FAIL) |\n",
    "\n",
    "### Result: **FAIL**\n",
    "\n",
    "The method did not successfully generalize to new task types. The concept-head projection failed on all three new semantic relationship types (synonym, antonym, person-occupation). This suggests the method is specialized to the specific task categories studied in the original work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT3 Results:\n",
      "{\n",
      "  \"results\": [\n",
      "    {\"task\": \"synonym\", \"proj\": false, \"raw\": false, \"proj_pred\": \"quick\", \"raw_pred\": \"quick\"},\n",
      "    {\"task\": \"antonym\", \"proj\": false, \"raw\": false, \"proj_pred\": \"down\", \"raw_pred\": \"down\"},\n",
      "    {\"task\": \"person-occupation\", \"proj\": false, \"raw\": false, \"proj_pred\": \"composer\", \"raw_pred\": \"composer\"}\n",
      "  ],\n",
      "  \"pass\": false,\n",
      "  \"count\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load GT3 results\n",
    "with open('/net/scratch2/smallyan/arithmetic_eval/evaluation/gt3_results.json', 'r') as f:\n",
    "    gt3_data = json.load(f)\n",
    "print(\"GT3 Results:\")\n",
    "print(json.dumps(gt3_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed Trial Examples Record\n",
    "\n",
    "### GT1 Failures (Model Generalization)\n",
    "- Trial 1: Athens - Greece + Japan -> Athens (expected: Tokyo)\n",
    "- Trial 2: Berlin - Germany + France -> Berlin (expected: Paris)\n",
    "\n",
    "### GT2 Failures (Data Generalization)\n",
    "- Trial 1: Brasilia - Brazil + Peru -> Brasilia (expected: Lima)\n",
    "- Trial 2: Bogota - Colombia + Ecuador -> Bogota (expected: Quito)\n",
    "\n",
    "### GT3 Failures (Method Generalizability)\n",
    "- Trial 1 (Synonym): big - large + quick -> quick (expected: fast)\n",
    "- Trial 2 (Antonym): hot - cold + down -> down (expected: up)\n",
    "- Trial 3 (Person-Occupation): Einstein - physicist + composer -> composer (expected: Mozart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Checklist Summary\n",
    "\n",
    "| Criterion | Result | Details |\n",
    "|-----------|--------|----------|\n",
    "| **GT1** Model Generalization | **PASS** | Grammatical task succeeded on Llama-3-8B (1/3 trials) |\n",
    "| **GT2** Data Generalization | **PASS** | Grammatical task succeeded on new verbs (1/3 trials) |\n",
    "| **GT3** Method Generalizability | **FAIL** | Method failed on all new task types (0/3 trials) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERALIZABILITY EVALUATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Repository: /net/scratch2/smallyan/arithmetic_eval\n",
      "Paper: Vector Arithmetic in Concept and Token Subspaces\n",
      "Original Model: Llama-2-7b-hf\n",
      "\n",
      "----------------------------------------\n",
      "CHECKLIST RESULTS\n",
      "----------------------------------------\n",
      "GT1 (Model Generalization): PASS\n",
      "GT2 (Data Generalization): PASS\n",
      "GT3 (Method Generalizability): FAIL\n",
      "\n",
      "----------------------------------------\n",
      "OVERALL ASSESSMENT\n",
      "----------------------------------------\n",
      "Passed 2/3 generalization criteria\n",
      "The findings demonstrate PARTIAL generalizability.\n",
      "\n",
      "The OV lens projection method shows promise for grammatical/morphological\n",
      "tasks (verb tense transformations) and generalizes to:\n",
      "- New models (Llama-3-8B)\n",
      "- New data (unseen verbs)\n",
      "\n",
      "However, the method does not generalize well to:\n",
      "- Different semantic relationship types (synonymy, antonymy, person-occupation)\n",
      "- Capital-country analogies (both on new models and new data)\n",
      "\n",
      "This suggests the identified \"token heads\" capture morphological transformations\n",
      "effectively, but \"concept heads\" may be more task-specific than claimed.\n"
     ]
    }
   ],
   "source": [
    "# Final Summary\n",
    "gt1_pass = gt1_data['pass']\n",
    "gt2_pass = gt2_data['pass']\n",
    "gt3_pass = gt3_data['pass']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERALIZABILITY EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nRepository: /net/scratch2/smallyan/arithmetic_eval\")\n",
    "print(f\"Paper: Vector Arithmetic in Concept and Token Subspaces\")\n",
    "print(f\"Original Model: Llama-2-7b-hf\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"CHECKLIST RESULTS\")\n",
    "print(\"-\"*40)\n",
    "print(f\"GT1 (Model Generalization): {'PASS' if gt1_pass else 'FAIL'}\")\n",
    "print(f\"GT2 (Data Generalization): {'PASS' if gt2_pass else 'FAIL'}\")\n",
    "print(f\"GT3 (Method Generalizability): {'PASS' if gt3_pass else 'FAIL'}\")\n",
    "\n",
    "pass_count = sum([gt1_pass, gt2_pass, gt3_pass])\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"OVERALL ASSESSMENT\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Passed {pass_count}/3 generalization criteria\")\n",
    "\n",
    "if pass_count == 3:\n",
    "    print(\"The findings demonstrate STRONG generalizability.\")\n",
    "elif pass_count >= 1:\n",
    "    print(\"The findings demonstrate PARTIAL generalizability.\")\n",
    "else:\n",
    "    print(\"The findings show LIMITED generalizability.\")\n",
    "\n",
    "print(\"\\nThe OV lens projection method shows promise for grammatical/morphological\")\n",
    "print(\"tasks (verb tense transformations) and generalizes to:\")\n",
    "print(\"- New models (Llama-3-8B)\")\n",
    "print(\"- New data (unseen verbs)\")\n",
    "print(\"\\nHowever, the method does not generalize well to:\")\n",
    "print(\"- Different semantic relationship types (synonymy, antonymy, person-occupation)\")\n",
    "print(\"- Capital-country analogies (both on new models and new data)\")\n",
    "print(\"\\nThis suggests the identified \\\"token heads\\\" capture morphological transformations\")\n",
    "print(\"effectively, but \\\"concept heads\\\" may be more task-specific than claimed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to generalization_eval_summary.json\n",
      "{\n",
      "  \"Checklist\": {\n",
      "    \"GT1_ModelGeneralization\": \"PASS\",\n",
      "    \"GT2_DataGeneralization\": \"PASS\",\n",
      "    \"GT3_MethodGeneralization\": \"FAIL\"\n",
      "  },\n",
      "  \"Rationale\": {\n",
      "    \"GT1_ModelGeneralization\": \"The OV projection method successfully predicted 1 out of 3 analogies on Meta-Llama-3-8B...\",\n",
      "    \"GT2_DataGeneralization\": \"The OV projection method successfully predicted 1 out of 3 analogies on NEW data instances...\",\n",
      "    \"GT3_MethodGeneralization\": \"The OV lens projection method failed on all 3 new task types tested...\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load and display the final summary JSON\n",
    "with open('/net/scratch2/smallyan/arithmetic_eval/evaluation/generalization_eval_summary.json', 'r') as f:\n",
    "    summary = json.load(f)\n",
    "print(\"Results saved to generalization_eval_summary.json\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
